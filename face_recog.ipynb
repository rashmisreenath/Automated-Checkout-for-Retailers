{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2236eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your id45\n"
     ]
    }
   ],
   "source": [
    "import cv2 #pip install opencv-contrib-python\n",
    "cam = cv2.VideoCapture(0)\n",
    "detector=cv2.CascadeClassifier('haar.xml')\n",
    "\n",
    "\n",
    "\n",
    "Id=input('enter your id')\n",
    "sampleNum=0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        #saving the captured face in the dataset folder\n",
    "        cv2.imwrite(\"D:/Down/store_images/User.\"+Id +'.'+ str(sampleNum) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        sampleNum=sampleNum+1\n",
    "        cv2.imshow('frame',img)\n",
    "    # break if the sample number is morethan 20\n",
    "    if sampleNum>20:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf61feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Down/store_images\\User.45.0.jpg\n",
      "D:/Down/store_images\\User.45.1.jpg\n",
      "D:/Down/store_images\\User.45.10.jpg\n",
      "D:/Down/store_images\\User.45.11.jpg\n",
      "D:/Down/store_images\\User.45.12.jpg\n",
      "D:/Down/store_images\\User.45.13.jpg\n",
      "D:/Down/store_images\\User.45.14.jpg\n",
      "D:/Down/store_images\\User.45.15.jpg\n",
      "D:/Down/store_images\\User.45.16.jpg\n",
      "D:/Down/store_images\\User.45.17.jpg\n",
      "D:/Down/store_images\\User.45.18.jpg\n",
      "D:/Down/store_images\\User.45.19.jpg\n",
      "D:/Down/store_images\\User.45.2.jpg\n",
      "D:/Down/store_images\\User.45.20.jpg\n",
      "D:/Down/store_images\\User.45.3.jpg\n",
      "D:/Down/store_images\\User.45.4.jpg\n",
      "D:/Down/store_images\\User.45.5.jpg\n",
      "D:/Down/store_images\\User.45.6.jpg\n",
      "D:/Down/store_images\\User.45.7.jpg\n",
      "D:/Down/store_images\\User.45.8.jpg\n",
      "D:/Down/store_images\\User.45.9.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "recognizer = cv2.face_LBPHFaceRecognizer.create()\n",
    "path=\"D:/Down/store_images\"\n",
    "def getImagesWithID(path):\n",
    "    imagePaths=[os.path.join(path,f) for f in os.listdir(path)]\n",
    "    faces=[]\n",
    "    IDs=[]\n",
    "\n",
    "    for imagepath in imagePaths:\n",
    "        faceImg=Image.open(imagepath).convert('L')\n",
    "        faceNp=np.array(faceImg,'uint8')\n",
    "        print(imagepath)\n",
    "        ID=int(os.path.split(imagepath)[-1].split(\".\")[1])\n",
    "        #dataset/User.1.3\n",
    "        faces.append(faceNp)\n",
    "        IDs.append(ID)\n",
    "        cv2.imshow(\"training\",faceNp)\n",
    "        cv2.waitKey(10)\n",
    "    return np.array(IDs),faces\n",
    "\n",
    "Ids,faces=getImagesWithID(path)\n",
    "recognizer.train(faces,Ids)\n",
    "recognizer.save('trainingData.yml')\n",
    "cv2.destroyAllWindows()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1fbd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 06:12:39.539 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haar.xml')\n",
    "\n",
    "rec=cv2.face_LBPHFaceRecognizer_create()\n",
    "rec.read(\"trainingData.yml\")\n",
    "def detect_faces(our_image):\n",
    "    img = np.array(our_image.convert('RGB'))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw rectangle around the faces\n",
    "    name='Unknown'\n",
    "    for (x, y, w, h) in faces:\n",
    "        # To draw a rectangle in a face\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "        id, uncertainty = rec.predict(gray[y:y + h, x:x + w])\n",
    "        print(id, uncertainty)\n",
    "\n",
    "        if (uncertainty< 53):\n",
    "            if (id == 45 or id == 3 or id == 5):\n",
    "                name = \"Rashmi\"\n",
    "                cv2.putText(img, name, (x, y + h), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2.0, (0, 0, 255))\n",
    "        else:\n",
    "            cv2.putText(img, 'Unknown', (x, y + h), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2.0, (0, 0, 255))\n",
    "\n",
    "\n",
    "    return img\n",
    "def main():\n",
    "    \"\"\"Face Recognition App\"\"\"\n",
    "\n",
    "    st.title(\"Streamlit Tutorial\")\n",
    "\n",
    "    html_temp = \"\"\"\n",
    "    <body style=\"background-color:red;\">\n",
    "    <div style=\"background-color:teal ;padding:10px\">\n",
    "    <h2 style=\"color:white;text-align:center;\">Face Recognition WebApp</h2>\n",
    "    </div>\n",
    "    </body>\n",
    "    \"\"\"\n",
    "    st.markdown(html_temp, unsafe_allow_html=True)\n",
    "\n",
    "    image_file = st.file_uploader(\"Upload Image\", type=['jpg', 'png', 'jpeg'])\n",
    "    if image_file is not None:\n",
    "        our_image = Image.open(image_file)\n",
    "        st.text(\"Original Image\")\n",
    "        st.image(our_image)\n",
    "\n",
    "    if st.button(\"Recognise\"):\n",
    "        result_img= detect_faces(our_image)\n",
    "        st.image(result_img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97bd897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7632b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
